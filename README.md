# [RE]-Random-synaptic-feedback-weights-support-error-backpropagation-for-deep-learning

![](figs/e1.png)

This repo is to replicate (partially) the result of T. P. Lillicrap, D. Cownden, D. B. Tweed, and C. J. Akerman, “Random synaptic feedback weights support error backpropagation for deep learning,” Nature Communications, vol. 7, pp. 1–10, 1AD.



`re1.py` is for the simple linear network.

`re2.py` is for the nolinear network on MNIST dataset.

`check2.py` is for the evaluation of the network on MNIST dataset.

Result in `figs/e1.png` seems great.

Performance of `figs/e2.png` matches the result in the paper also, whereas the change of angle is not so close to that of the paper.